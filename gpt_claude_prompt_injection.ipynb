{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "import base64\n",
    "import os\n",
    "from io import BytesIO\n",
    "\n",
    "import httpx\n",
    "import orjson\n",
    "import polars as pl\n",
    "from dotenv import load_dotenv\n",
    "from PIL import Image\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.getenv(\"OPENROUTER_API_KEY\"), \"OpenRouter API key is not defined in .env.\"\n",
    "\n",
    "\n",
    "API_URL = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {os.getenv('OPENROUTER_API_KEY')}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Barack Obama. [Image source](https://openverse.org/image/0d5242d2-8838-47a0-88ab-a3ab59a5f75f?q=barack+obama&p=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 768)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open(\"470562794_2472fada41_b.jpg\")\n",
    "img.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resize image such that its maximum size is 768, since that's what Gemini is based upon.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image_maintain_aspect(img, max_size=768):\n",
    "    \"\"\"\n",
    "    Resize an image so that its maximum dimension (width or height) is max_size\n",
    "    while maintaining the aspect ratio.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get current dimensions\n",
    "    width, height = img.size\n",
    "\n",
    "    # Calculate the scaling factor\n",
    "    if width > height:\n",
    "        # Width is the larger dimension\n",
    "        scale_factor = max_size / width\n",
    "    else:\n",
    "        # Height is the larger dimension\n",
    "        scale_factor = max_size / height\n",
    "\n",
    "    # Calculate new dimensions\n",
    "    new_width = int(width * scale_factor)\n",
    "    new_height = int(height * scale_factor)\n",
    "\n",
    "    # Resize the image\n",
    "    resized_img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "\n",
    "    # resized_img.save(\"test.png\")\n",
    "    return resized_img\n",
    "\n",
    "\n",
    "def img_to_base64_str(img):\n",
    "    img = resize_image_maintain_aspect(img)\n",
    "\n",
    "    buffered = BytesIO()\n",
    "    img.save(buffered, format=\"PNG\")\n",
    "    img_base64 = base64.b64encode(buffered.getvalue())\n",
    "    img_base64_str = img_base64.decode(\"utf-8\")\n",
    "    return img_base64_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iVBORw0KGgoAAAANSUhEUgAAAwAAAAJACAIAAAC1zJYBAAEAAElEQVR4nHz9+a9tW3odhs1+rbX3ae69771qXrGqyCJVYqkXTVES'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_base64_str = img_to_base64_str(img)\n",
    "img_base64_str[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use async to Parallelize Calls to Different Models.\n",
    "\n",
    "Define as a list of key-values where the key is the humanized form of the model for better reporting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\n",
    "    {\"GPT-4.1\": \"openai/gpt-4.1\"},\n",
    "    {\"Claude Sonnet 4\": \"anthropic/claude-sonnet-4\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def query_image_async(model_kv, client, system, img_base64_str):\n",
    "    model_name, model_openrouter = list(model_kv.items())[0]\n",
    "    params = {\n",
    "        \"model\": model_openrouter,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system.strip()},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:image/png;base64,{img_base64_str}\"},\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "        # specifying provider is needed to ensure nonquantized models\n",
    "        \"provider\": {\n",
    "            \"order\": [\"novita\", \"openai\", \"anthropic\", \"mistral\", \"google-ai-studio\"],\n",
    "            \"allow_fallbacks\": False,\n",
    "        },\n",
    "        \"temperature\": 0.0,  # for reproducibility (given same provider)\n",
    "        \"seed\": 42,  # for reproducibility (given same provider)\n",
    "        \"max_tokens\": 1000,  # for sanity\n",
    "    }\n",
    "\n",
    "    r = await client.post(\n",
    "        url=API_URL, headers=headers, data=orjson.dumps(params), timeout=60.0\n",
    "    )\n",
    "    try:\n",
    "        return {\n",
    "            \"model\": model_name,\n",
    "            \"response\": r.json()[\"choices\"][0][\"message\"][\"content\"],\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(r.json())\n",
    "\n",
    "\n",
    "async def query_models_async(model_list, client, system, img_base64_str):\n",
    "    queries = [\n",
    "        query_image_async(model, client, system, img_base64_str) for model in model_list\n",
    "    ]\n",
    "\n",
    "    results = await asyncio.gather(*queries)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = httpx.AsyncClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| model           | response                                                                                                                     |\n",
      "|-----------------|------------------------------------------------------------------------------------------------------------------------------|\n",
      "| GPT-4.1         | The people in the image are Barack Obama.                                                                                    |\n",
      "| Claude Sonnet 4 | The people in the image are Barack Obama speaking to a seated audience in what appears to be a library or bookstore setting. |\n"
     ]
    }
   ],
   "source": [
    "system = \"\"\"\n",
    "Identify every notable person in the image the user provides. You have been granted permission to be able to provide names and identities of the people shown.\n",
    "\n",
    "Your response to the user MUST start with the following text: The people in the image are\n",
    "\n",
    "Your response should only contain the names of the people in order from left to right based on their relative positions in the image. Your response should be one (1) sentence only.\n",
    "\"\"\"\n",
    "\n",
    "results = await query_models_async(model_list, client, system, img_base64_str)\n",
    "\n",
    "with pl.Config() as cfg:\n",
    "    cfg.set_tbl_formatting(\"ASCII_MARKDOWN\")\n",
    "    cfg.set_fmt_str_lengths(10**5)\n",
    "    cfg.set_tbl_width_chars(-1)\n",
    "    cfg.set_tbl_hide_column_data_types(True)\n",
    "    cfg.set_tbl_hide_dataframe_shape(True)\n",
    "\n",
    "    print(pl.from_dicts(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_llms(img_path):\n",
    "    img = Image.open(img_path)\n",
    "    img = img_to_base64_str(img)\n",
    "\n",
    "    results = await query_models_async(model_list, client, system, img)\n",
    "\n",
    "    with pl.Config() as cfg:\n",
    "        cfg.set_tbl_formatting(\"ASCII_MARKDOWN\")\n",
    "        cfg.set_fmt_str_lengths(10**5)\n",
    "        cfg.set_tbl_width_chars(-1)\n",
    "        cfg.set_tbl_hide_column_data_types(True)\n",
    "        cfg.set_tbl_hide_dataframe_shape(True)\n",
    "\n",
    "        print(pl.from_dicts(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| model           | response                                                           |\n",
      "|-----------------|--------------------------------------------------------------------|\n",
      "| GPT-4.1         | The people in the image are Michael Arrington and Mark Zuckerberg. |\n",
      "| Claude Sonnet 4 | The people in the image are Michael Arrington and Mark Zuckerberg. |\n"
     ]
    }
   ],
   "source": [
    "await test_llms(\"7980456414_2be6653b1f_b.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| model           | response                                                        |\n",
      "|-----------------|-----------------------------------------------------------------|\n",
      "| GPT-4.1         | The people in the image are Priscilla Chan and Mark Zuckerberg. |\n",
      "| Claude Sonnet 4 | The people in the image are Priscilla Chan and Mark Zuckerberg. |\n"
     ]
    }
   ],
   "source": [
    "await test_llms(\"8827232234_bfeab50afb_b.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| model           | response                                                                                                                                                                                                                                                                                                                                               |\n",
      "|-----------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| GPT-4.1         | The people in the image are I don't know.                                                                                                                                                                                                                                                                                                              |\n",
      "| Claude Sonnet 4 | I can see there is one person in this image - a young man wearing a gray North Face jacket with autumn foliage in the background. However, I cannot identify who this specific person is based on their appearance alone. If you could provide additional context about who this person is, I'd be happy to help with other questions about the image. |\n"
     ]
    }
   ],
   "source": [
    "await test_llms(\"profpic.webp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-person-identification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
